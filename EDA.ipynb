{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "This notebook conducts comprehensive exploratory data analysis on multiple datasets including:\n",
        "- GDP per capita (World Bank)\n",
        "- Public health expenditure as share of GDP\n",
        "- Share of population that disagrees vaccines are effective\n",
        "- Share of population that is urban\n",
        "\n",
        "## Objectives\n",
        "1. Load and examine each dataset\n",
        "2. Understand data structure and quality\n",
        "3. Identify missing values and data issues\n",
        "4. Perform statistical summaries\n",
        "5. Create visualizations\n",
        "6. Explore relationships between variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn-darkgrid')\n",
        "    except:\n",
        "        plt.style.use('ggplot')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(f\"Seaborn version: {sns.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CSV files\n",
        "data_dir = Path('.')\n",
        "\n",
        "# Load GDP per capita data\n",
        "gdp_df = pd.read_csv('gdp-per-capita-worldbank.csv')\n",
        "print(\"GDP per capita data loaded\")\n",
        "print(f\"Shape: {gdp_df.shape}\")\n",
        "\n",
        "# Load public health expenditure data\n",
        "health_exp_df = pd.read_csv('public-health-expenditure-share-gdp.csv')\n",
        "print(\"\\nPublic health expenditure data loaded\")\n",
        "print(f\"Shape: {health_exp_df.shape}\")\n",
        "\n",
        "# Load vaccine disagreement data\n",
        "vaccine_df = pd.read_csv('share-disagrees-vaccines-are-effective.csv')\n",
        "print(\"\\nVaccine disagreement data loaded\")\n",
        "print(f\"Shape: {vaccine_df.shape}\")\n",
        "\n",
        "# Load urban population data\n",
        "urban_df = pd.read_csv('share-of-population-urban.csv')\n",
        "print(\"\\nUrban population data loaded\")\n",
        "print(f\"Shape: {urban_df.shape}\")\n",
        "\n",
        "# Load measles reporting data (from Excel file 1)\n",
        "excel1_df = pd.read_csv('measles-reporting-data.csv')\n",
        "print(\"\\nMeasles reporting data loaded\")\n",
        "print(f\"Shape: {excel1_df.shape}\")\n",
        "\n",
        "# Load household size composition data (from Excel file 2)\n",
        "excel2_df = pd.read_csv('undesa_pd_2022_hh-size-composition.csv')\n",
        "print(\"\\nHousehold size composition data loaded\")\n",
        "print(f\"Shape: {excel2_df.shape}\")\n",
        "print(f\"Shape: {excel2_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define column names for easier reference\n",
        "gdp_col = [col for col in gdp_df.columns if 'GDP' in col][0]\n",
        "health_col = [col for col in health_exp_df.columns if 'health' in col.lower() or 'expenditure' in col.lower()][0]\n",
        "vaccine_col = [col for col in vaccine_df.columns if 'vaccine' in col.lower() or 'disagree' in col.lower()][0]\n",
        "urban_col = [col for col in urban_df.columns if 'urban' in col.lower()][0]\n",
        "\n",
        "print(\"Column names identified:\")\n",
        "print(f\"  GDP column: {gdp_col}\")\n",
        "print(f\"  Health expenditure column: {health_col}\")\n",
        "print(f\"  Vaccine disagreement column: {vaccine_col}\")\n",
        "print(f\"  Urban population column: {urban_col}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display basic information about each dataset\n",
        "datasets = {\n",
        "    'GDP per capita': gdp_df,\n",
        "    'Health Expenditure': health_exp_df,\n",
        "    'Vaccine Disagreement': vaccine_df,\n",
        "    'Urban Population': urban_df\n",
        "}\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{name} Dataset\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"\\nColumn names:\")\n",
        "    print(df.columns.tolist())\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n",
        "    print(f\"\\nData types:\")\n",
        "    print(df.dtypes)\n",
        "    print(f\"\\nBasic statistics:\")\n",
        "    print(df.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Quality Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values in each dataset\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{name} - Missing Values\")\n",
        "    print(f\"{'='*60}\")\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df)) * 100\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing Count': missing,\n",
        "        'Missing Percentage': missing_pct\n",
        "    })\n",
        "    print(missing_df[missing_df['Missing Count'] > 0])\n",
        "    if missing_df['Missing Count'].sum() == 0:\n",
        "        print(\"No missing values found!\")\n",
        "    \n",
        "    # Check for duplicates\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"\\nDuplicate rows: {duplicates}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Temporal Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze temporal coverage for each dataset\n",
        "for name, df in datasets.items():\n",
        "    if 'Year' in df.columns:\n",
        "        print(f\"\\n{name} - Year Range:\")\n",
        "        print(f\"  Min Year: {df['Year'].min()}\")\n",
        "        print(f\"  Max Year: {df['Year'].max()}\")\n",
        "        print(f\"  Year Range: {df['Year'].max() - df['Year'].min()} years\")\n",
        "        print(f\"  Unique Years: {df['Year'].nunique()}\")\n",
        "        print(f\"  Unique Countries: {df['Entity'].nunique() if 'Entity' in df.columns else 'N/A'}\")\n",
        "        \n",
        "        # Year distribution\n",
        "        year_counts = df['Year'].value_counts().sort_index()\n",
        "        print(f\"\\n  Years with most data points:\")\n",
        "        print(year_counts.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Geographic Coverage Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze geographic coverage\n",
        "for name, df in datasets.items():\n",
        "    if 'Entity' in df.columns:\n",
        "        print(f\"\\n{name} - Geographic Coverage:\")\n",
        "        print(f\"  Total unique countries/entities: {df['Entity'].nunique()}\")\n",
        "        print(f\"\\n  Sample of countries:\")\n",
        "        print(df['Entity'].unique()[:20])\n",
        "        \n",
        "        if 'World regions according to OWID' in df.columns:\n",
        "            print(f\"\\n  World regions:\")\n",
        "            regions = df['World regions according to OWID'].value_counts()\n",
        "            print(regions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualizations - GDP per Capita\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean column name for GDP\n",
        "gdp_col = [col for col in gdp_df.columns if 'GDP' in col][0]\n",
        "\n",
        "# Plot 1: GDP per capita distribution\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Distribution of GDP per capita\n",
        "axes[0, 0].hist(gdp_df[gdp_col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('Distribution of GDP per Capita', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('GDP per Capita (PPP, constant 2021 international $)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Log scale distribution\n",
        "axes[0, 1].hist(np.log10(gdp_df[gdp_col].dropna()), bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_title('Distribution of GDP per Capita (Log Scale)', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Log10(GDP per Capita)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# GDP over time (average across all countries)\n",
        "gdp_by_year = gdp_df.groupby('Year')[gdp_col].mean()\n",
        "axes[1, 0].plot(gdp_by_year.index, gdp_by_year.values, linewidth=2, marker='o')\n",
        "axes[1, 0].set_title('Average GDP per Capita Over Time', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Year')\n",
        "axes[1, 0].set_ylabel('Average GDP per Capita')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Top 10 countries by latest GDP\n",
        "latest_year = gdp_df['Year'].max()\n",
        "latest_gdp = gdp_df[gdp_df['Year'] == latest_year].nlargest(10, gdp_col)\n",
        "axes[1, 1].barh(latest_gdp['Entity'], latest_gdp[gdp_col])\n",
        "axes[1, 1].set_title(f'Top 10 Countries by GDP per Capita ({latest_year})', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('GDP per Capita')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualizations - Health Expenditure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get health expenditure column name\n",
        "health_col = [col for col in health_exp_df.columns if 'health' in col.lower() or 'expenditure' in col.lower()][0]\n",
        "\n",
        "# Plot health expenditure analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Distribution\n",
        "axes[0, 0].hist(health_exp_df[health_col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('Distribution of Health Expenditure (% of GDP)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Health Expenditure (% of GDP)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Over time\n",
        "health_by_year = health_exp_df.groupby('Year')[health_col].mean()\n",
        "axes[0, 1].plot(health_by_year.index, health_by_year.values, linewidth=2, marker='o', color='green')\n",
        "axes[0, 1].set_title('Average Health Expenditure Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Year')\n",
        "axes[0, 1].set_ylabel('Average Health Expenditure (% of GDP)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Top countries by latest health expenditure\n",
        "latest_year_health = health_exp_df['Year'].max()\n",
        "latest_health = health_exp_df[health_exp_df['Year'] == latest_year_health].nlargest(10, health_col)\n",
        "axes[1, 0].barh(latest_health['Entity'], latest_health[health_col], color='green')\n",
        "axes[1, 0].set_title(f'Top 10 Countries by Health Expenditure ({latest_year_health})', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Health Expenditure (% of GDP)')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Box plot by decade\n",
        "health_exp_df['Decade'] = (health_exp_df['Year'] // 10) * 10\n",
        "recent_data = health_exp_df[health_exp_df['Decade'] >= 2000]\n",
        "axes[1, 1].boxplot([recent_data[recent_data['Decade'] == d][health_col].dropna() \n",
        "                    for d in sorted(recent_data['Decade'].unique())],\n",
        "                   labels=sorted(recent_data['Decade'].unique()))\n",
        "axes[1, 1].set_title('Health Expenditure Distribution by Decade', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Decade')\n",
        "axes[1, 1].set_ylabel('Health Expenditure (% of GDP)')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualizations - Vaccine Disagreement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get vaccine column name\n",
        "vaccine_col = [col for col in vaccine_df.columns if 'vaccine' in col.lower() or 'disagree' in col.lower()][0]\n",
        "\n",
        "# Plot vaccine disagreement analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Distribution\n",
        "axes[0, 0].hist(vaccine_df[vaccine_col].dropna(), bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[0, 0].set_title('Distribution of Vaccine Disagreement (%)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Share that Disagrees Vaccines are Effective (%)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Over time\n",
        "vaccine_by_year = vaccine_df.groupby('Year')[vaccine_col].mean()\n",
        "axes[0, 1].plot(vaccine_by_year.index, vaccine_by_year.values, linewidth=2, marker='o', color='orange')\n",
        "axes[0, 1].set_title('Average Vaccine Disagreement Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Year')\n",
        "axes[0, 1].set_ylabel('Average Disagreement (%)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Countries with highest disagreement (latest year)\n",
        "latest_year_vaccine = 2024\n",
        "latest_vaccine = vaccine_df[vaccine_df['Year'] == latest_year_vaccine].nlargest(10, vaccine_col)\n",
        "axes[1, 0].barh(latest_vaccine['Entity'], latest_vaccine[vaccine_col], color='orange')\n",
        "axes[1, 0].set_title(f'Top 10 Countries by Vaccine Disagreement ({latest_year_vaccine})', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Disagreement (%)')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Countries with lowest disagreement\n",
        "lowest_vaccine = vaccine_df[vaccine_df['Year'] == latest_year_vaccine].nsmallest(10, vaccine_col)\n",
        "axes[1, 1].barh(lowest_vaccine['Entity'], lowest_vaccine[vaccine_col], color='lightgreen')\n",
        "axes[1, 1].set_title(f'Top 10 Countries with Lowest Vaccine Disagreement ({latest_year_vaccine})', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Disagreement (%)')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Visualizations - Urban Population\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualizations - Measles Reporting Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load measles data if not already loaded\n",
        "if 'excel1_df' not in locals():\n",
        "    excel1_df = pd.read_csv('measles-reporting-data.csv')\n",
        "\n",
        "# Clean column names (remove BOM if present)\n",
        "excel1_df.columns = excel1_df.columns.str.replace('\\ufeff', '')\n",
        "\n",
        "# Display basic info\n",
        "print(\"Measles Reporting Data Overview:\")\n",
        "print(f\"Shape: {excel1_df.shape}\")\n",
        "print(f\"\\nColumns: {excel1_df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(excel1_df.head())\n",
        "print(f\"\\nData types:\")\n",
        "print(excel1_df.dtypes)\n",
        "print(f\"\\nMissing values:\")\n",
        "print(excel1_df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize measles reporting data\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Get column names\n",
        "cases_col = 'Total confirmed  measles cases'\n",
        "incidence_col = 'Measles incidence rate per 1\\'000\\'000  total population'\n",
        "lab_col = 'Lab confirmed'\n",
        "pop_col = 'Total population'\n",
        "\n",
        "# 1. Distribution of total confirmed cases\n",
        "axes[0, 0].hist(excel1_df[cases_col].dropna(), bins=50, edgecolor='black', alpha=0.7, color='red')\n",
        "axes[0, 0].set_title('Distribution of Total Confirmed Measles Cases', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Total Confirmed Cases')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_yscale('log')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Measles cases over time (global)\n",
        "cases_by_year = excel1_df.groupby('Year')[cases_col].sum()\n",
        "axes[0, 1].plot(cases_by_year.index, cases_by_year.values, linewidth=2, marker='o', color='red')\n",
        "axes[0, 1].set_title('Global Measles Cases Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Year')\n",
        "axes[0, 1].set_ylabel('Total Cases')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Incidence rate over time (average)\n",
        "incidence_by_year = excel1_df.groupby('Year')[incidence_col].mean()\n",
        "axes[0, 2].plot(incidence_by_year.index, incidence_by_year.values, linewidth=2, marker='o', color='orange')\n",
        "axes[0, 2].set_title('Average Measles Incidence Rate Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 2].set_xlabel('Year')\n",
        "axes[0, 2].set_ylabel('Incidence Rate (per 1M population)')\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Top 10 countries by total cases (latest year)\n",
        "latest_year_measles = excel1_df['Year'].max()\n",
        "latest_measles = excel1_df[excel1_df['Year'] == latest_year_measles].nlargest(10, cases_col)\n",
        "axes[1, 0].barh(latest_measles['Member State'], latest_measles[cases_col], color='red')\n",
        "axes[1, 0].set_title(f'Top 10 Countries by Measles Cases ({latest_year_measles})', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Total Cases')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 5. Top 10 countries by incidence rate (latest year)\n",
        "latest_incidence = excel1_df[excel1_df['Year'] == latest_year_measles].nlargest(10, incidence_col)\n",
        "axes[1, 1].barh(latest_incidence['Member State'], latest_incidence[incidence_col], color='orange')\n",
        "axes[1, 1].set_title(f'Top 10 Countries by Incidence Rate ({latest_year_measles})', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Incidence Rate (per 1M)')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 6. Cases by region (latest year)\n",
        "region_cases = excel1_df[excel1_df['Year'] == latest_year_measles].groupby('Region')[cases_col].sum().sort_values(ascending=False)\n",
        "axes[1, 2].bar(range(len(region_cases)), region_cases.values, color='crimson')\n",
        "axes[1, 2].set_xticks(range(len(region_cases)))\n",
        "axes[1, 2].set_xticklabels(region_cases.index, rotation=45, ha='right')\n",
        "axes[1, 2].set_title(f'Measles Cases by Region ({latest_year_measles})', fontsize=14, fontweight='bold')\n",
        "axes[1, 2].set_ylabel('Total Cases')\n",
        "axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional measles analysis: Confirmation types breakdown\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Lab confirmed vs other types over time\n",
        "lab_by_year = excel1_df.groupby('Year')[lab_col].sum()\n",
        "epi_by_year = excel1_df.groupby('Year')['Epidemiologically linked'].sum()\n",
        "clinical_by_year = excel1_df.groupby('Year')['Clinically compatible'].sum()\n",
        "\n",
        "axes[0].plot(lab_by_year.index, lab_by_year.values, label='Lab Confirmed', linewidth=2, marker='o')\n",
        "axes[0].plot(epi_by_year.index, epi_by_year.values, label='Epidemiologically Linked', linewidth=2, marker='s')\n",
        "axes[0].plot(clinical_by_year.index, clinical_by_year.values, label='Clinically Compatible', linewidth=2, marker='^')\n",
        "axes[0].set_title('Measles Cases by Confirmation Type Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Year')\n",
        "axes[0].set_ylabel('Number of Cases')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Heatmap: Cases by region and year (recent years)\n",
        "recent_years = sorted(excel1_df['Year'].unique())[-10:]  # Last 10 years\n",
        "region_year = excel1_df[excel1_df['Year'].isin(recent_years)].pivot_table(\n",
        "    values=cases_col, index='Region', columns='Year', aggfunc='sum', fill_value=0\n",
        ")\n",
        "sns.heatmap(region_year, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[1], cbar_kws={'label': 'Total Cases'})\n",
        "axes[1].set_title('Measles Cases Heatmap: Region vs Year', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Year')\n",
        "axes[1].set_ylabel('Region')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Visualizations - Household Size Composition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load household size data if not already loaded\n",
        "if 'excel2_df' not in locals():\n",
        "    excel2_df = pd.read_csv('undesa_pd_2022_hh-size-composition.csv')\n",
        "\n",
        "# Clean column names (remove BOM if present)\n",
        "excel2_df.columns = excel2_df.columns.str.replace('\\ufeff', '')\n",
        "\n",
        "# Remove empty columns\n",
        "excel2_df = excel2_df.loc[:, ~excel2_df.columns.str.contains('^Unnamed')]\n",
        "excel2_df = excel2_df.dropna(axis=1, how='all')\n",
        "\n",
        "# Parse reference date to extract year\n",
        "def extract_year(date_str):\n",
        "    try:\n",
        "        if pd.isna(date_str):\n",
        "            return None\n",
        "        # Handle different date formats: \"1/7/10\", \"19/10/2015\", etc.\n",
        "        parts = str(date_str).split('/')\n",
        "        if len(parts) == 3:\n",
        "            year = parts[2]\n",
        "            if len(year) == 2:\n",
        "                # Convert 2-digit year to 4-digit (assuming 2000s)\n",
        "                year = '20' + year if int(year) < 50 else '19' + year\n",
        "            return int(year)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "excel2_df['Year'] = excel2_df['Reference date (dd/mm/yyyy)'].apply(extract_year)\n",
        "\n",
        "# Get household size column\n",
        "hh_size_col = 'Average household size (number of members)'\n",
        "\n",
        "# Convert household size to numeric, handling non-numeric values (like \"..\")\n",
        "excel2_df[hh_size_col] = pd.to_numeric(excel2_df[hh_size_col], errors='coerce')\n",
        "\n",
        "# Display basic info\n",
        "print(\"Household Size Composition Data Overview:\")\n",
        "print(f\"Shape: {excel2_df.shape}\")\n",
        "print(f\"\\nColumns: {excel2_df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(excel2_df.head())\n",
        "print(f\"\\nData types:\")\n",
        "print(excel2_df.dtypes)\n",
        "print(f\"\\nMissing values:\")\n",
        "print(excel2_df.isnull().sum())\n",
        "print(f\"\\nUnique countries: {excel2_df['Country or area'].nunique()}\")\n",
        "print(f\"\\nData source categories: {excel2_df['Data source category'].value_counts()}\")\n",
        "print(f\"\\nHousehold size statistics:\")\n",
        "print(excel2_df[hh_size_col].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize household size composition data\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Filter out invalid household sizes\n",
        "valid_data = excel2_df[excel2_df[hh_size_col].notna() & (excel2_df[hh_size_col] > 0) & (excel2_df[hh_size_col] < 20)]\n",
        "\n",
        "# 1. Distribution of household sizes\n",
        "axes[0, 0].hist(valid_data[hh_size_col], bins=40, edgecolor='black', alpha=0.7, color='teal')\n",
        "axes[0, 0].set_title('Distribution of Average Household Size', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Average Household Size (members)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Household size over time (global average)\n",
        "if valid_data['Year'].notna().sum() > 0:\n",
        "    hh_by_year = valid_data.groupby('Year')[hh_size_col].mean()\n",
        "    axes[0, 1].plot(hh_by_year.index, hh_by_year.values, linewidth=2, marker='o', color='teal')\n",
        "    axes[0, 1].set_title('Global Average Household Size Over Time', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Year')\n",
        "    axes[0, 1].set_ylabel('Average Household Size')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Household size by data source\n",
        "source_means = valid_data.groupby('Data source category')[hh_size_col].mean().sort_values(ascending=False)\n",
        "axes[0, 2].barh(range(len(source_means)), source_means.values, color='teal')\n",
        "axes[0, 2].set_yticks(range(len(source_means)))\n",
        "axes[0, 2].set_yticklabels(source_means.index)\n",
        "axes[0, 2].set_title('Average Household Size by Data Source', fontsize=14, fontweight='bold')\n",
        "axes[0, 2].set_xlabel('Average Household Size')\n",
        "axes[0, 2].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 4. Countries with largest household sizes (most recent data)\n",
        "if valid_data['Year'].notna().sum() > 0:\n",
        "    latest_year_hh = valid_data['Year'].max()\n",
        "    latest_hh_data = valid_data[valid_data['Year'] == latest_year_hh]\n",
        "    # Get most recent entry per country\n",
        "    latest_hh_data = latest_hh_data.sort_values('Year').drop_duplicates(subset='Country or area', keep='last')\n",
        "    largest_hh = latest_hh_data.nlargest(10, hh_size_col)\n",
        "    axes[1, 0].barh(largest_hh['Country or area'], largest_hh[hh_size_col], color='teal')\n",
        "    axes[1, 0].set_title(f'Top 10 Countries by Household Size ({latest_year_hh})', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Average Household Size')\n",
        "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 5. Countries with smallest household sizes\n",
        "if valid_data['Year'].notna().sum() > 0:\n",
        "    smallest_hh = latest_hh_data.nsmallest(10, hh_size_col)\n",
        "    axes[1, 1].barh(smallest_hh['Country or area'], smallest_hh[hh_size_col], color='lightblue')\n",
        "    axes[1, 1].set_title(f'Top 10 Countries with Smallest Households ({latest_year_hh})', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Average Household Size')\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 6. Box plot by data source\n",
        "source_data = [valid_data[valid_data['Data source category'] == source][hh_size_col].dropna() \n",
        "               for source in valid_data['Data source category'].value_counts().head(5).index]\n",
        "axes[1, 2].boxplot(source_data, labels=valid_data['Data source category'].value_counts().head(5).index)\n",
        "axes[1, 2].set_title('Household Size Distribution by Data Source', fontsize=14, fontweight='bold')\n",
        "axes[1, 2].set_ylabel('Average Household Size')\n",
        "axes[1, 2].tick_params(axis='x', rotation=45)\n",
        "axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional household size analysis: Trends for selected countries\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Get countries with multiple data points over time\n",
        "country_years = valid_data.groupby('Country or area')['Year'].count()\n",
        "countries_with_history = country_years[country_years >= 5].index[:10]  # Top 10 countries with most data points\n",
        "\n",
        "# Plot trends for selected countries\n",
        "for country in countries_with_history[:5]:\n",
        "    country_data = valid_data[valid_data['Country or area'] == country].sort_values('Year')\n",
        "    axes[0].plot(country_data['Year'], country_data[hh_size_col], marker='o', label=country, linewidth=2)\n",
        "\n",
        "axes[0].set_title('Household Size Trends: Selected Countries', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Year')\n",
        "axes[0].set_ylabel('Average Household Size')\n",
        "axes[0].legend(loc='best', fontsize=8)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Distribution comparison: recent vs older data\n",
        "if valid_data['Year'].notna().sum() > 0:\n",
        "    recent_cutoff = valid_data['Year'].quantile(0.75)\n",
        "    recent_data = valid_data[valid_data['Year'] >= recent_cutoff][hh_size_col]\n",
        "    older_data = valid_data[valid_data['Year'] < recent_cutoff][hh_size_col]\n",
        "    \n",
        "    axes[1].hist(older_data.dropna(), bins=30, alpha=0.6, label=f'Before {int(recent_cutoff)}', color='lightcoral', edgecolor='black')\n",
        "    axes[1].hist(recent_data.dropna(), bins=30, alpha=0.6, label=f'{int(recent_cutoff)} and later', color='teal', edgecolor='black')\n",
        "    axes[1].set_title('Household Size Distribution: Historical Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Average Household Size')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Relationship Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get urban population column name\n",
        "urban_col = [col for col in urban_df.columns if 'urban' in col.lower()][0]\n",
        "\n",
        "# Plot urban population analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Distribution\n",
        "axes[0, 0].hist(urban_df[urban_col].dropna(), bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
        "axes[0, 0].set_title('Distribution of Urban Population (%)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Urban Population (% of total)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Global trend over time\n",
        "urban_by_year = urban_df.groupby('Year')[urban_col].mean()\n",
        "axes[0, 1].plot(urban_by_year.index, urban_by_year.values, linewidth=2, marker='o', color='purple')\n",
        "axes[0, 1].set_title('Average Urban Population Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Year')\n",
        "axes[0, 1].set_ylabel('Average Urban Population (%)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Most urbanized countries (latest year)\n",
        "latest_year_urban = urban_df['Year'].max()\n",
        "latest_urban = urban_df[urban_df['Year'] == latest_year_urban].nlargest(10, urban_col)\n",
        "axes[1, 0].barh(latest_urban['Entity'], latest_urban[urban_col], color='purple')\n",
        "axes[1, 0].set_title(f'Top 10 Most Urbanized Countries ({latest_year_urban})', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Urban Population (%)')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Least urbanized countries\n",
        "lowest_urban = urban_df[urban_df['Year'] == latest_year_urban].nsmallest(10, urban_col)\n",
        "axes[1, 1].barh(lowest_urban['Entity'], lowest_urban[urban_col], color='brown')\n",
        "axes[1, 1].set_title(f'Top 10 Least Urbanized Countries ({latest_year_urban})', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Urban Population (%)')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge datasets to explore relationships\n",
        "# Find a year with good coverage across all datasets\n",
        "\n",
        "# Find common years across datasets\n",
        "common_years = set(gdp_df['Year'].unique())\n",
        "common_years = common_years.intersection(set(health_exp_df['Year'].unique()))\n",
        "common_years = common_years.intersection(set(vaccine_df['Year'].unique()))\n",
        "common_years = common_years.intersection(set(urban_df['Year'].unique()))\n",
        "\n",
        "print(f\"Common years across all datasets: {sorted(common_years)}\")\n",
        "\n",
        "# Find the year with the most countries having data in all datasets\n",
        "best_year = None\n",
        "max_countries = 0\n",
        "\n",
        "for year in sorted(common_years, reverse=True):\n",
        "    gdp_countries = set(gdp_df[gdp_df['Year'] == year]['Code'].unique())\n",
        "    health_countries = set(health_exp_df[health_exp_df['Year'] == year]['Code'].unique())\n",
        "    vaccine_countries = set(vaccine_df[vaccine_df['Year'] == year]['Code'].unique())\n",
        "    urban_countries = set(urban_df[urban_df['Year'] == year]['Code'].unique())\n",
        "    \n",
        "    common_countries = gdp_countries & health_countries & vaccine_countries & urban_countries\n",
        "    if len(common_countries) > max_countries:\n",
        "        max_countries = len(common_countries)\n",
        "        best_year = year\n",
        "\n",
        "# Use the year with best coverage, or fall back to 2019/2020 if available\n",
        "if best_year and max_countries >= 10:\n",
        "    analysis_year = best_year\n",
        "    print(f\"\\nBest year for analysis: {analysis_year} ({max_countries} countries with complete data)\")\n",
        "else:\n",
        "    # Try 2019 or 2020 as they typically have good coverage\n",
        "    for candidate_year in [2019, 2020, 2018]:\n",
        "        if candidate_year in common_years:\n",
        "            analysis_year = candidate_year\n",
        "            gdp_countries = set(gdp_df[gdp_df['Year'] == analysis_year]['Code'].unique())\n",
        "            health_countries = set(health_exp_df[health_exp_df['Year'] == analysis_year]['Code'].unique())\n",
        "            vaccine_countries = set(vaccine_df[vaccine_df['Year'] == analysis_year]['Code'].unique())\n",
        "            urban_countries = set(urban_df[urban_df['Year'] == analysis_year]['Code'].unique())\n",
        "            common_countries = gdp_countries & health_countries & vaccine_countries & urban_countries\n",
        "            print(f\"\\nUsing year {analysis_year} for relationship analysis ({len(common_countries)} countries with complete data)\")\n",
        "            break\n",
        "    else:\n",
        "        analysis_year = max(common_years)\n",
        "        print(f\"\\nUsing most recent common year {analysis_year} for relationship analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge datasets for the analysis year using inner join to only keep countries with all data\n",
        "merged_df = gdp_df[gdp_df['Year'] == analysis_year][['Entity', 'Code', gdp_col]].copy()\n",
        "merged_df = merged_df.merge(\n",
        "    health_exp_df[health_exp_df['Year'] == analysis_year][['Code', health_col]], \n",
        "    on='Code', how='inner'  # Changed to inner to only keep countries with health data\n",
        ")\n",
        "merged_df = merged_df.merge(\n",
        "    vaccine_df[vaccine_df['Year'] == analysis_year][['Code', vaccine_col]], \n",
        "    on='Code', how='inner'  # Changed to inner to only keep countries with vaccine data\n",
        ")\n",
        "merged_df = merged_df.merge(\n",
        "    urban_df[urban_df['Year'] == analysis_year][['Code', urban_col]], \n",
        "    on='Code', how='inner'  # Changed to inner to only keep countries with urban data\n",
        ")\n",
        "\n",
        "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
        "print(f\"\\nMerged dataset columns: {merged_df.columns.tolist()}\")\n",
        "print(f\"\\nNumber of countries with complete data: {len(merged_df)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(merged_df.head(10))\n",
        "print(f\"\\nMissing values in merged dataset:\")\n",
        "print(merged_df.isnull().sum())\n",
        "print(f\"\\nData ranges:\")\n",
        "print(f\"  GDP per capita: ${merged_df[gdp_col].min():,.2f} - ${merged_df[gdp_col].max():,.2f}\")\n",
        "print(f\"  Health expenditure: {merged_df[health_col].min():.2f}% - {merged_df[health_col].max():.2f}%\")\n",
        "print(f\"  Vaccine disagreement: {merged_df[vaccine_col].min():.2f}% - {merged_df[vaccine_col].max():.2f}%\")\n",
        "print(f\"  Urban population: {merged_df[urban_col].min():.2f}% - {merged_df[urban_col].max():.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create correlation matrix for numeric variables\n",
        "numeric_cols = [gdp_col, health_col, vaccine_col, urban_col]\n",
        "correlation_df = merged_df[numeric_cols].corr()\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_df, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix Between Variables', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12.5. Correlation Analysis: Metrics vs Measles Cases\n",
        "\n",
        "This section analyzes the Spearman rank correlation between various socioeconomic and health metrics and measles incidence rate to identify potential relationships. Spearman correlation is used as it's more robust to outliers (few countries may dominate cases/incidence).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare measles data for correlation analysis\n",
        "# Load measles data if not already loaded\n",
        "if 'excel1_df' not in locals():\n",
        "    excel1_df = pd.read_csv('measles-reporting-data.csv')\n",
        "    excel1_df.columns = excel1_df.columns.str.replace('\\ufeff', '')\n",
        "\n",
        "# Get measles cases column\n",
        "cases_col = 'Total confirmed  measles cases'\n",
        "incidence_col = 'Measles incidence rate per 1\\'000\\'000  total population'\n",
        "\n",
        "# Find a year with good coverage for measles data\n",
        "measles_years = excel1_df['Year'].unique()\n",
        "print(f\"Available years in measles data: {sorted(measles_years)}\")\n",
        "\n",
        "# Find year with most countries reporting measles data\n",
        "year_counts = excel1_df.groupby('Year')['ISO country code'].nunique().sort_values(ascending=False)\n",
        "best_measles_year = year_counts.index[0]\n",
        "print(f\"\\nYear with most measles data: {best_measles_year} ({year_counts.iloc[0]} countries)\")\n",
        "\n",
        "# Use the same analysis_year from relationship analysis, or find best overlap\n",
        "# Try to use a year that has both measles data and other metrics\n",
        "overlap_years = set(measles_years).intersection(set(gdp_df['Year'].unique()))\n",
        "overlap_years = overlap_years.intersection(set(health_exp_df['Year'].unique()))\n",
        "overlap_years = overlap_years.intersection(set(urban_df['Year'].unique()))\n",
        "\n",
        "if overlap_years:\n",
        "    # Find year with most complete data\n",
        "    correlation_year = None\n",
        "    max_countries = 0\n",
        "    for year in sorted(overlap_years, reverse=True):\n",
        "        measles_codes = set(excel1_df[excel1_df['Year'] == year]['ISO country code'].dropna().unique())\n",
        "        gdp_codes = set(gdp_df[gdp_df['Year'] == year]['Code'].unique())\n",
        "        health_codes = set(health_exp_df[health_exp_df['Year'] == year]['Code'].unique())\n",
        "        urban_codes = set(urban_df[urban_df['Year'] == year]['Code'].unique())\n",
        "        \n",
        "        common_codes = measles_codes & gdp_codes & health_codes & urban_codes\n",
        "        if len(common_codes) > max_countries:\n",
        "            max_countries = len(common_codes)\n",
        "            correlation_year = year\n",
        "    \n",
        "    if correlation_year:\n",
        "        print(f\"\\nUsing year {correlation_year} for correlation analysis ({max_countries} countries)\")\n",
        "    else:\n",
        "        correlation_year = max(overlap_years)\n",
        "        print(f\"\\nUsing year {correlation_year} for correlation analysis\")\n",
        "else:\n",
        "    # Fallback to best available year\n",
        "    correlation_year = best_measles_year\n",
        "    print(f\"\\nUsing year {correlation_year} for correlation analysis (limited overlap)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge measles data with other metrics for correlation analysis\n",
        "correlation_df = excel1_df[excel1_df['Year'] == correlation_year][['ISO country code', cases_col, incidence_col]].copy()\n",
        "correlation_df = correlation_df.rename(columns={'ISO country code': 'Code'})\n",
        "\n",
        "# Merge with GDP\n",
        "correlation_df = correlation_df.merge(\n",
        "    gdp_df[gdp_df['Year'] == correlation_year][['Code', gdp_col]], \n",
        "    on='Code', how='inner'\n",
        ")\n",
        "\n",
        "# Merge with Health Expenditure\n",
        "correlation_df = correlation_df.merge(\n",
        "    health_exp_df[health_exp_df['Year'] == correlation_year][['Code', health_col]], \n",
        "    on='Code', how='inner'\n",
        ")\n",
        "\n",
        "# Merge with Urban Population\n",
        "correlation_df = correlation_df.merge(\n",
        "    urban_df[urban_df['Year'] == correlation_year][['Code', urban_col]], \n",
        "    on='Code', how='inner'\n",
        ")\n",
        "\n",
        "# Try to merge with Vaccine Disagreement if available for this year\n",
        "if correlation_year in vaccine_df['Year'].values:\n",
        "    correlation_df = correlation_df.merge(\n",
        "        vaccine_df[vaccine_df['Year'] == correlation_year][['Code', vaccine_col]], \n",
        "        on='Code', how='left'  # Left join since vaccine data may be sparse\n",
        "    )\n",
        "else:\n",
        "    print(f\"Note: Vaccine disagreement data not available for year {correlation_year}\")\n",
        "\n",
        "# Try to merge with Household Size if available (use most recent year per country)\n",
        "# Using country_converter to handle ISO code conversions\n",
        "import country_converter as coco\n",
        "cc = coco.CountryConverter()\n",
        "\n",
        "# Define hh_size_col if not already defined\n",
        "if 'hh_size_col' not in globals():\n",
        "    hh_size_col = 'Average household size (number of members)'\n",
        "\n",
        "if 'excel2_df' not in locals():\n",
        "    excel2_df = pd.read_csv('undesa_pd_2022_hh-size-composition.csv')\n",
        "    excel2_df.columns = excel2_df.columns.str.replace('\\ufeff', '')\n",
        "    excel2_df = excel2_df.loc[:, ~excel2_df.columns.str.contains('^Unnamed')]\n",
        "    excel2_df[hh_size_col] = pd.to_numeric(excel2_df[hh_size_col], errors='coerce')\n",
        "    \n",
        "    # Define extract_year function if not already defined\n",
        "    if 'extract_year' not in globals():\n",
        "        def extract_year(date_str):\n",
        "            try:\n",
        "                if pd.isna(date_str):\n",
        "                    return None\n",
        "                parts = str(date_str).split('/')\n",
        "                if len(parts) == 3:\n",
        "                    year = parts[2]\n",
        "                    if len(year) == 2:\n",
        "                        year = '20' + year if int(year) < 50 else '19' + year\n",
        "                    return int(year)\n",
        "            except:\n",
        "                return None\n",
        "    \n",
        "    excel2_df['Year'] = excel2_df['Reference date (dd/mm/yyyy)'].apply(extract_year)\n",
        "\n",
        "# Get most recent household size per country\n",
        "hh_latest = excel2_df[excel2_df[hh_size_col].notna()].sort_values('Year').drop_duplicates(subset='ISO Code', keep='last')\n",
        "\n",
        "# Convert numeric ISO codes to 3-letter ISO codes using country_converter\n",
        "try:\n",
        "    # Convert numeric ISO codes to ISO3 (3-letter codes)\n",
        "    # Try UNcode first (UN numeric codes follow ISO-numeric closely)\n",
        "    # If that doesn't work well, country_converter will auto-detect\n",
        "    iso_numeric_codes = hh_latest['ISO Code'].astype(int).astype(str).tolist()\n",
        "    iso3_codes = cc.convert(names=iso_numeric_codes, src='UNcode', to='ISO3', not_found=None)\n",
        "    \n",
        "    # Handle case where convert returns a list or Series\n",
        "    if isinstance(iso3_codes, (list, pd.Series)):\n",
        "        hh_latest['Code'] = iso3_codes\n",
        "    else:\n",
        "        # If it's a single value (shouldn't happen but handle it)\n",
        "        hh_latest['Code'] = [iso3_codes] * len(hh_latest)\n",
        "    \n",
        "    # Filter out rows where conversion failed (Code is None, 'not found', or invalid)\n",
        "    hh_latest_clean = hh_latest[\n",
        "        hh_latest['Code'].notna() & \n",
        "        (hh_latest['Code'] != 'not found') &\n",
        "        (hh_latest['Code'].str.len() == 3)  # ISO3 codes are exactly 3 characters\n",
        "    ].copy()\n",
        "    \n",
        "    if len(hh_latest_clean) > 0:\n",
        "        # Merge household size data using ISO3 codes (same as other datasets)\n",
        "        correlation_df = correlation_df.merge(\n",
        "            hh_latest_clean[['Code', hh_size_col]], \n",
        "            on='Code', how='left'\n",
        "        )\n",
        "        \n",
        "        # Report matching statistics\n",
        "        matched_count = correlation_df[hh_size_col].notna().sum()\n",
        "        total_count = len(correlation_df)\n",
        "        print(f\"\\nHousehold size data merged: {matched_count}/{total_count} countries matched using ISO3 codes\")\n",
        "        \n",
        "        if matched_count < total_count:\n",
        "            unmatched = correlation_df[correlation_df[hh_size_col].isna()]['Code'].tolist()\n",
        "            print(f\"  Unmatched countries (sample): {unmatched[:10]}\")\n",
        "    else:\n",
        "        print(\"Note: No household size data could be converted to ISO3 codes\")\n",
        "        raise ValueError(\"Conversion failed\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not merge household size data using country_converter: {e}\")\n",
        "    print(\"  Attempting fallback to name-based matching...\")\n",
        "    # Fallback to name-based matching\n",
        "    try:\n",
        "        if 'Entity' in gdp_df.columns:\n",
        "            country_map = gdp_df[gdp_df['Year'] == correlation_year][['Code', 'Entity']].drop_duplicates()\n",
        "            correlation_df_temp = correlation_df.merge(country_map, on='Code', how='left')\n",
        "            \n",
        "            hh_latest_clean = hh_latest[['Country or area', hh_size_col]].copy()\n",
        "            correlation_df_temp = correlation_df_temp.merge(\n",
        "                hh_latest_clean, \n",
        "                left_on='Entity', right_on='Country or area', how='left'\n",
        "            )\n",
        "            \n",
        "            correlation_df = correlation_df_temp.drop(columns=['Entity', 'Country or area'], errors='ignore')\n",
        "            matched_count = correlation_df[hh_size_col].notna().sum()\n",
        "            total_count = len(correlation_df)\n",
        "            print(f\"  Fallback: Used name-based matching - {matched_count}/{total_count} countries matched\")\n",
        "    except Exception as e2:\n",
        "        print(f\"  Fallback also failed: {e2}\")\n",
        "\n",
        "print(f\"\\nMerged dataset for correlation analysis:\")\n",
        "print(f\"Shape: {correlation_df.shape}\")\n",
        "print(f\"Countries: {len(correlation_df)}\")\n",
        "print(f\"\\nColumns: {correlation_df.columns.tolist()}\")\n",
        "print(f\"\\nMissing values:\")\n",
        "print(correlation_df.isnull().sum())\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(correlation_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Spearman correlations with measles incidence rate (including p-values)\n",
        "# Using Spearman rank correlation as it's more robust to outliers\n",
        "# (few countries may dominate cases/incidence)\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Prepare metrics for correlation\n",
        "metrics = {\n",
        "    'GDP per Capita': gdp_col,\n",
        "    'Health Expenditure (% GDP)': health_col,\n",
        "    'Urban Population (%)': urban_col,\n",
        "}\n",
        "\n",
        "if vaccine_col in correlation_df.columns:\n",
        "    metrics['Vaccine Disagreement (%)'] = vaccine_col\n",
        "\n",
        "if hh_size_col in correlation_df.columns:\n",
        "    metrics['Household Size'] = hh_size_col\n",
        "\n",
        "# Calculate correlations with incidence rate only (including p-values)\n",
        "# Note: Using incidence rate per 1M population instead of total cases\n",
        "correlations_incidence = {}\n",
        "pvalues_incidence = {}\n",
        "sample_sizes_incidence = {}\n",
        "\n",
        "# Remove rows with missing values for each metric\n",
        "for metric_name, metric_col in metrics.items():\n",
        "    if metric_col in correlation_df.columns:\n",
        "        # Correlation with incidence rate (Spearman rank correlation)\n",
        "        data_subset = correlation_df[[incidence_col, metric_col]].dropna()\n",
        "        if len(data_subset) > 2:  # Need at least 3 points for correlation\n",
        "            corr_result = spearmanr(data_subset[incidence_col], data_subset[metric_col])\n",
        "            correlations_incidence[metric_name] = corr_result.statistic\n",
        "            pvalues_incidence[metric_name] = corr_result.pvalue\n",
        "            sample_sizes_incidence[metric_name] = len(data_subset)\n",
        "\n",
        "# Helper function to format significance\n",
        "def format_significance(pval):\n",
        "    if pd.isna(pval):\n",
        "        return ''\n",
        "    elif pval < 0.001:\n",
        "        return '***'\n",
        "    elif pval < 0.01:\n",
        "        return '**'\n",
        "    elif pval < 0.05:\n",
        "        return '*'\n",
        "    elif pval < 0.1:\n",
        "        return '.'\n",
        "    else:\n",
        "        return 'ns'\n",
        "\n",
        "# Create correlation dataframe with p-values (incidence rate only)\n",
        "corr_results = pd.DataFrame({\n",
        "    'Metric': list(correlations_incidence.keys()),\n",
        "    'Correlation': [correlations_incidence.get(m, np.nan) for m in correlations_incidence.keys()],\n",
        "    'P-value': [pvalues_incidence.get(m, np.nan) for m in correlations_incidence.keys()],\n",
        "    'Significance': [format_significance(pvalues_incidence.get(m, np.nan)) for m in correlations_incidence.keys()],\n",
        "    'N': [sample_sizes_incidence.get(m, np.nan) for m in correlations_incidence.keys()]\n",
        "})\n",
        "\n",
        "# Sort by absolute correlation value\n",
        "corr_results['Abs_Correlation'] = corr_results['Correlation'].abs()\n",
        "corr_results = corr_results.sort_values('Abs_Correlation', ascending=False).drop(columns=['Abs_Correlation'])\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SPEARMAN RANK CORRELATIONS: METRICS vs MEASLES INCIDENCE RATE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nYear: {correlation_year}\")\n",
        "print(f\"Number of countries analyzed: {len(correlation_df)}\")\n",
        "print(f\"\\nSignificance levels: *** p<0.001, ** p<0.01, * p<0.05, . p<0.1, ns = not significant\")\n",
        "print(f\"\\nCorrelation Results:\")\n",
        "print(corr_results.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize correlations with p-values (incidence rate only)\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "# Bar plot of correlations with incidence rate (including significance indicators)\n",
        "colors = ['red' if x < 0 else 'blue' for x in corr_results['Correlation']]\n",
        "bars = ax.barh(corr_results['Metric'], corr_results['Correlation'], color=colors, alpha=0.7)\n",
        "ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "ax.set_xlabel('Spearman Rank Correlation Coefficient', fontsize=12)\n",
        "ax.set_title(f'Spearman Correlation with Measles Incidence Rate\\n(Year {correlation_year})', fontsize=14, fontweight='bold')\n",
        "ax.set_xlim(-1, 1)\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# Add significance indicators to bars\n",
        "for i, (bar, sig) in enumerate(zip(bars, corr_results['Significance'])):\n",
        "    if sig and sig != 'ns':\n",
        "        x_pos = bar.get_width()\n",
        "        if x_pos < 0:\n",
        "            x_pos = x_pos - 0.05\n",
        "        else:\n",
        "            x_pos = x_pos + 0.05\n",
        "        ax.text(x_pos, bar.get_y() + bar.get_height()/2, sig, \n",
        "                va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Add legend for significance levels\n",
        "fig.text(0.5, 0.02, 'Significance: *** p<0.001, ** p<0.01, * p<0.05, . p<0.1', \n",
        "         ha='center', fontsize=10, style='italic')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(bottom=0.1)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create scatter plots showing relationships with p-values\n",
        "# Define format_significance function if not already defined\n",
        "if 'format_significance' not in globals():\n",
        "    def format_significance(pval):\n",
        "        if pd.isna(pval):\n",
        "            return ''\n",
        "        elif pval < 0.001:\n",
        "            return '***'\n",
        "        elif pval < 0.01:\n",
        "            return '**'\n",
        "        elif pval < 0.05:\n",
        "            return '*'\n",
        "        elif pval < 0.1:\n",
        "            return '.'\n",
        "        else:\n",
        "            return 'ns'\n",
        "\n",
        "# Determine number of metrics to plot\n",
        "n_metrics = len([m for m in metrics.values() if m in correlation_df.columns])\n",
        "n_cols = min(3, n_metrics)\n",
        "n_rows = (n_metrics + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
        "if n_metrics == 1:\n",
        "    axes = [axes]\n",
        "elif n_rows == 1:\n",
        "    axes = axes if isinstance(axes, np.ndarray) else [axes]\n",
        "else:\n",
        "    axes = axes.flatten()\n",
        "\n",
        "plot_idx = 0\n",
        "for metric_name, metric_col in metrics.items():\n",
        "    if metric_col in correlation_df.columns and plot_idx < len(axes):\n",
        "        # Remove missing values - using incidence rate instead of total cases\n",
        "        plot_data = correlation_df[[incidence_col, metric_col]].dropna()\n",
        "        \n",
        "        if len(plot_data) > 2:\n",
        "            ax = axes[plot_idx]\n",
        "            ax.scatter(plot_data[metric_col], plot_data[incidence_col], alpha=0.6, s=50, color='crimson')\n",
        "            ax.set_xlabel(metric_name, fontsize=11)\n",
        "            ax.set_ylabel('Measles Incidence Rate (per 1M)', fontsize=11)\n",
        "            # Format title with correlation and p-value\n",
        "            corr_val = correlations_incidence.get(metric_name, np.nan)\n",
        "            pval = pvalues_incidence.get(metric_name, np.nan)\n",
        "            sig = format_significance(pval)\n",
        "            if not pd.isna(pval):\n",
        "                title = f'{metric_name} vs Measles Incidence Rate\\n(={corr_val:.3f}, p={pval:.4f}{sig})'\n",
        "            else:\n",
        "                title = f'{metric_name} vs Measles Incidence Rate\\n(={corr_val:.3f})'\n",
        "            ax.set_title(title, fontsize=12, fontweight='bold')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add trend line\n",
        "            if len(plot_data) > 1:\n",
        "                z = np.polyfit(plot_data[metric_col], plot_data[incidence_col], 1)\n",
        "                p = np.poly1d(z)\n",
        "                x_line = np.linspace(plot_data[metric_col].min(), plot_data[metric_col].max(), 100)\n",
        "                ax.plot(x_line, p(x_line), \"r--\", alpha=0.8, linewidth=2)\n",
        "            \n",
        "            plot_idx += 1\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(plot_idx, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive correlation heatmap (incidence rate only)\n",
        "# Prepare data for heatmap\n",
        "heatmap_data = correlation_df[[incidence_col]].copy()\n",
        "\n",
        "# Add metrics\n",
        "for metric_name, metric_col in metrics.items():\n",
        "    if metric_col in correlation_df.columns:\n",
        "        heatmap_data[metric_name] = correlation_df[metric_col]\n",
        "\n",
        "# Calculate correlation matrix using Spearman rank correlation\n",
        "corr_matrix = heatmap_data.corr(method='spearman')\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, \n",
        "            xticklabels=True, yticklabels=True)\n",
        "plt.title(f'Spearman Correlation Matrix: Measles Incidence Rate vs Metrics\\n(Year {correlation_year})', \n",
        "          fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(corr_matrix.round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create scatter plots to visualize relationships\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Remove rows with missing values for plotting\n",
        "plot_df = merged_df[numeric_cols].dropna()\n",
        "\n",
        "# GDP vs Health Expenditure\n",
        "axes[0, 0].scatter(plot_df[gdp_col], plot_df[health_col], alpha=0.6, s=50)\n",
        "axes[0, 0].set_xlabel('GDP per Capita')\n",
        "axes[0, 0].set_ylabel('Health Expenditure (% of GDP)')\n",
        "axes[0, 0].set_title('GDP per Capita vs Health Expenditure', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "# Add trend line\n",
        "z = np.polyfit(plot_df[gdp_col], plot_df[health_col], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[0, 0].plot(plot_df[gdp_col], p(plot_df[gdp_col]), \"r--\", alpha=0.8)\n",
        "\n",
        "# GDP vs Urban Population\n",
        "axes[0, 1].scatter(plot_df[gdp_col], plot_df[urban_col], alpha=0.6, s=50, color='green')\n",
        "axes[0, 1].set_xlabel('GDP per Capita')\n",
        "axes[0, 1].set_ylabel('Urban Population (%)')\n",
        "axes[0, 1].set_title('GDP per Capita vs Urban Population', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "z = np.polyfit(plot_df[gdp_col], plot_df[urban_col], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[0, 1].plot(plot_df[gdp_col], p(plot_df[gdp_col]), \"r--\", alpha=0.8)\n",
        "\n",
        "# Health Expenditure vs Vaccine Disagreement\n",
        "axes[1, 0].scatter(plot_df[health_col], plot_df[vaccine_col], alpha=0.6, s=50, color='orange')\n",
        "axes[1, 0].set_xlabel('Health Expenditure (% of GDP)')\n",
        "axes[1, 0].set_ylabel('Vaccine Disagreement (%)')\n",
        "axes[1, 0].set_title('Health Expenditure vs Vaccine Disagreement', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "z = np.polyfit(plot_df[health_col], plot_df[vaccine_col], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[1, 0].plot(plot_df[health_col], p(plot_df[health_col]), \"r--\", alpha=0.8)\n",
        "\n",
        "# Urban Population vs Vaccine Disagreement\n",
        "axes[1, 1].scatter(plot_df[urban_col], plot_df[vaccine_col], alpha=0.6, s=50, color='purple')\n",
        "axes[1, 1].set_xlabel('Urban Population (%)')\n",
        "axes[1, 1].set_ylabel('Vaccine Disagreement (%)')\n",
        "axes[1, 1].set_title('Urban Population vs Vaccine Disagreement', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "z = np.polyfit(plot_df[urban_col], plot_df[vaccine_col], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[1, 1].plot(plot_df[urban_col], p(plot_df[urban_col]), \"r--\", alpha=0.8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive summary statistics\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE SUMMARY STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(\"-\" * 80)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if numeric_cols:\n",
        "        summary = df[numeric_cols].describe()\n",
        "        print(summary)\n",
        "        \n",
        "        # Additional statistics\n",
        "        for col in numeric_cols:\n",
        "            if col != 'Year' and col != 'Code':\n",
        "                print(f\"\\n{col}:\")\n",
        "                print(f\"  Skewness: {df[col].skew():.4f}\")\n",
        "                print(f\"  Kurtosis: {df[col].kurtosis():.4f}\")\n",
        "                print(f\"  Median: {df[col].median():.4f}\")\n",
        "                print(f\"  IQR: {df[col].quantile(0.75) - df[col].quantile(0.25):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Key Findings and Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate key insights\n",
        "print(\"=\"*80)\n",
        "print(\"KEY FINDINGS AND INSIGHTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# GDP Insights\n",
        "latest_gdp_data = gdp_df[gdp_df['Year'] == gdp_df['Year'].max()]\n",
        "print(f\"\\n1. GDP PER CAPITA:\")\n",
        "print(f\"   - Latest year: {gdp_df['Year'].max()}\")\n",
        "print(f\"   - Countries with data: {latest_gdp_data['Entity'].nunique()}\")\n",
        "print(f\"   - Average GDP per capita: ${latest_gdp_data[gdp_col].mean():,.2f}\")\n",
        "print(f\"   - Median GDP per capita: ${latest_gdp_data[gdp_col].median():,.2f}\")\n",
        "print(f\"   - Highest: {latest_gdp_data.loc[latest_gdp_data[gdp_col].idxmax(), 'Entity']} (${latest_gdp_data[gdp_col].max():,.2f})\")\n",
        "print(f\"   - Lowest: {latest_gdp_data.loc[latest_gdp_data[gdp_col].idxmin(), 'Entity']} (${latest_gdp_data[gdp_col].min():,.2f})\")\n",
        "\n",
        "# Health Expenditure Insights\n",
        "latest_health_data = health_exp_df[health_exp_df['Year'] == health_exp_df['Year'].max()]\n",
        "print(f\"\\n2. HEALTH EXPENDITURE:\")\n",
        "print(f\"   - Latest year: {health_exp_df['Year'].max()}\")\n",
        "print(f\"   - Countries with data: {latest_health_data['Entity'].nunique()}\")\n",
        "print(f\"   - Average health expenditure: {latest_health_data[health_col].mean():.2f}% of GDP\")\n",
        "print(f\"   - Median health expenditure: {latest_health_data[health_col].median():.2f}% of GDP\")\n",
        "print(f\"   - Highest: {latest_health_data.loc[latest_health_data[health_col].idxmax(), 'Entity']} ({latest_health_data[health_col].max():.2f}%)\")\n",
        "print(f\"   - Lowest: {latest_health_data.loc[latest_health_data[health_col].idxmin(), 'Entity']} ({latest_health_data[health_col].min():.2f}%)\")\n",
        "\n",
        "# Vaccine Insights\n",
        "latest_vaccine_data = vaccine_df[vaccine_df['Year'] == vaccine_df['Year'].max()]\n",
        "print(f\"\\n3. VACCINE DISAGREEMENT:\")\n",
        "print(f\"   - Latest year: {vaccine_df['Year'].max()}\")\n",
        "print(f\"   - Countries with data: {latest_vaccine_data['Entity'].nunique()}\")\n",
        "print(f\"   - Average disagreement: {latest_vaccine_data[vaccine_col].mean():.2f}%\")\n",
        "print(f\"   - Median disagreement: {latest_vaccine_data[vaccine_col].median():.2f}%\")\n",
        "print(f\"   - Highest: {latest_vaccine_data.loc[latest_vaccine_data[vaccine_col].idxmax(), 'Entity']} ({latest_vaccine_data[vaccine_col].max():.2f}%)\")\n",
        "print(f\"   - Lowest: {latest_vaccine_data.loc[latest_vaccine_data[vaccine_col].idxmin(), 'Entity']} ({latest_vaccine_data[vaccine_col].min():.2f}%)\")\n",
        "\n",
        "# Urban Population Insights\n",
        "latest_urban_data = urban_df[urban_df['Year'] == urban_df['Year'].max()]\n",
        "print(f\"\\n4. URBAN POPULATION:\")\n",
        "print(f\"   - Latest year: {urban_df['Year'].max()}\")\n",
        "print(f\"   - Countries with data: {latest_urban_data['Entity'].nunique()}\")\n",
        "print(f\"   - Average urban population: {latest_urban_data[urban_col].mean():.2f}%\")\n",
        "print(f\"   - Median urban population: {latest_urban_data[urban_col].median():.2f}%\")\n",
        "print(f\"   - Most urbanized: {latest_urban_data.loc[latest_urban_data[urban_col].idxmax(), 'Entity']} ({latest_urban_data[urban_col].max():.2f}%)\")\n",
        "print(f\"   - Least urbanized: {latest_urban_data.loc[latest_urban_data[urban_col].idxmin(), 'Entity']} ({latest_urban_data[urban_col].min():.2f}%)\")\n",
        "\n",
        "# Relationship Insights\n",
        "if len(plot_df) > 0:\n",
        "    print(f\"\\n5. RELATIONSHIPS (Year {analysis_year}, {len(plot_df)} countries):\")\n",
        "    print(f\"   - GDP vs Health Expenditure correlation: {plot_df[gdp_col].corr(plot_df[health_col]):.3f}\")\n",
        "    print(f\"   - GDP vs Urban Population correlation: {plot_df[gdp_col].corr(plot_df[urban_col]):.3f}\")\n",
        "    print(f\"   - Health Expenditure vs Vaccine Disagreement correlation: {plot_df[health_col].corr(plot_df[vaccine_col]):.3f}\")\n",
        "    print(f\"   - Urban Population vs Vaccine Disagreement correlation: {plot_df[urban_col].corr(plot_df[vaccine_col]):.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "4002",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
